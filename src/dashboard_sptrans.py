import streamlit as st
import pandas as pd
import sqlite3
import os
from itertools import combinations
from geopy.distance import great_circle

# --- Configura√ß√£o da P√°gina ---
st.set_page_config(
    page_title="Dashboard de An√°lise SPTrans",
    page_icon="üöå",
    layout="wide"
)

# --- Fun√ß√µes de An√°lise e Carregamento de Dados ---

@st.cache_data # Cache para n√£o recarregar os dados a cada intera√ß√£o
def load_data(db_path):
    """Carrega os dados da tabela de resultados do banco de dados."""
    if not os.path.exists(db_path):
        return None
    try:
        conn = sqlite3.connect(db_path)
        # Carrega apenas as colunas necess√°rias para otimizar a mem√≥ria
        query = "SELECT timestamp_analise, id_onibus, letreiro_linha, posicao_atual_lat, posicao_atual_lon FROM resultados_analise;"
        df = pd.read_sql_query(query, conn)
        conn.close()
        df['timestamp_analise'] = pd.to_datetime(df['timestamp_analise'])
        return df
    except Exception as e:
        st.error(f"Erro ao carregar os dados: {e}")
        return None

@st.cache_data
def load_line_names(csv_path):
    """Carrega o mapeamento de linhas do arquivo CSV."""
    if not os.path.exists(csv_path):
        return None
    try:
        df_linhas = pd.read_csv(csv_path)
        df_linhas['nome_linha'] = df_linhas['sentido_ida'] + ' / ' + df_linhas['sentido_volta']
        return df_linhas
    except Exception as e:
        st.error(f"Erro ao carregar o arquivo de nomes de linha: {e}")
        return None

def enrich_with_line_names(result_df, lines_df):
    """Adiciona nomes descritivos das linhas ao dataframe de resultado."""
    if lines_df is None or result_df.empty:
        result_df['nome_linha'] = result_df.index
        return result_df.set_index('nome_linha')

    result_df_copy = result_df.reset_index().rename(columns={'index': 'letreiro_linha'})
    result_df_copy['letreiro_numerico'] = result_df_copy['letreiro_linha'].apply(lambda x: x.split('-')[0])
    result_df_copy['tipo_letreiro'] = result_df_copy['letreiro_linha'].apply(lambda x: int(x.split('-')[1]) if '-' in x else 10)

    lines_df_copy = lines_df.copy()
    lines_df_copy['letreiro_numerico'] = lines_df_copy['letreiro_numerico'].astype(str)
    lines_df_copy['tipo_letreiro'] = pd.to_numeric(lines_df_copy['tipo_letreiro'])

    enriched_df = pd.merge(result_df_copy, lines_df_copy[['letreiro_numerico', 'tipo_letreiro', 'nome_linha']], on=['letreiro_numerico', 'tipo_letreiro'], how='left')
    enriched_df['nome_linha'] = enriched_df['nome_linha'].fillna(enriched_df['letreiro_linha'])
    enriched_df.set_index('nome_linha', inplace=True)
    
    original_cols = [col for col in result_df.columns]
    return enriched_df[original_cols]

@st.cache_data
def analyze_stuck_buses(df):
    """Processa o dataframe para identificar √¥nibus parados."""
    df_copy = df.copy()
    df_copy['horario_posicao_dt'] = pd.to_datetime(df_copy['timestamp_analise'])
    
    analise_parada = df_copy.sort_values('horario_posicao_dt').groupby('id_onibus').agg(
        letreiro_linha=('letreiro_linha', 'first'),
        tempo_decorrido_min=('horario_posicao_dt', lambda x: (x.max() - x.min()).total_seconds() / 60),
        distancia_km=('posicao_atual_lat', lambda x: great_circle((x.iloc[0], df_copy.loc[x.index[0], 'posicao_atual_lon']), (x.iloc[-1], df_copy.loc[x.index[-1], 'posicao_atual_lon'])).kilometers if len(x) > 1 else 0)
    )
    return analise_parada[(analise_parada['tempo_decorrido_min'] > 10) & (analise_parada['distancia_km'] < 0.1)]

@st.cache_data
def analyze_bunched_buses(df, threshold_meters=200):
    """Processa o dataframe para identificar 'comboios' de √¥nibus."""
    bunched_events = []
    for (timestamp, letreiro), group in df.groupby(['timestamp_analise', 'letreiro_linha']):
        if len(group) > 1:
            # Sort by latitude to make proximity checks more efficient
            group_sorted = group.sort_values('posicao_atual_lat')
            
            # Check distance between consecutive buses after sorting
            # This is a simplification and might miss some bunched buses
            # but it's much faster than combinations for large groups
            for i in range(len(group_sorted) - 1):
                bus1 = group_sorted.iloc[i]
                bus2 = group_sorted.iloc[i+1]
                distancia = great_circle((bus1.posicao_atual_lat, bus1.posicao_atual_lon), (bus2.posicao_atual_lat, bus2.posicao_atual_lon)).meters
                if distancia < threshold_meters:
                    bunched_events.append({'letreiro_linha': letreiro})
    return pd.DataFrame(bunched_events)

# --- T√≠tulo e Carregamento de Dados ---
st.title("üöå Dashboard de An√°lise da Frota SPTrans")
st.markdown("Este painel apresenta insights sobre a opera√ß√£o da frota de √¥nibus de S√£o Paulo, com base nos dados coletados da API Olho Vivo.")

DB_PATH = os.path.join('data', 'sptrans_data.db')
CSV_PATH = os.path.join('data', 'todas_as_linhas.csv')

df_raw = load_data(DB_PATH)
df_linhas = load_line_names(CSV_PATH)

if df_raw is None or df_raw.empty:
    st.warning("Ainda n√£o h√° dados para exibir ou o banco de dados n√£o foi encontrado. Por favor, inicie os coletores e aguarde a gera√ß√£o de dados.")
else:
    # --- Barra Lateral ---
    st.sidebar.header("Sobre o Projeto")
    st.sidebar.info("Este √© um projeto de portf√≥lio de Engenharia de Dados que demonstra uma pipeline completa: coleta, armazenamento, processamento e visualiza√ß√£o de dados.")
    st.sidebar.header("Filtros")
    linhas_unicas = sorted(df_raw['letreiro_linha'].unique().tolist())
    linha_selecionada = st.sidebar.selectbox("Filtrar por Linha (para o mapa)", ["Todas"] + linhas_unicas)

    # --- Filtragem de Dados ---
    df_mapa = df_raw.copy()
    if linha_selecionada != "Todas":
        df_mapa = df_raw[df_raw['letreiro_linha'] == linha_selecionada]

    # --- An√°lises ---
    onibus_parados_df = analyze_stuck_buses(df_raw)
    bunched_df = analyze_bunched_buses(df_raw)

    # --- KPIs ---
    st.header("Vis√£o Geral da Coleta")
    kpi1, kpi2, kpi3 = st.columns(3)
    kpi1.metric("Total de Registros Coletados", f"{len(df_raw):,}".replace(",", "."))
    kpi2.metric("Linhas Monitoradas", df_raw['letreiro_linha'].nunique())
    kpi3.metric("Eventos de 'Comboio' Detectados", len(bunched_df))

    # Fun√ß√£o para carregar m√©tricas de qualidade ETL da pasta dedicada
    @st.cache_data
    def load_etl_insights(relatorios_path):
        """Carrega relat√≥rios de qualidade de dados da pasta analise_banco_dados/relatorios/."""
        try:
            # Carregar amostra previs√µes (taxa de completude)
            previsoes_path = os.path.join(relatorios_path, 'amostra_previsoes_completas.txt')
            if os.path.exists(previsoes_path):
                df_previsoes = pd.read_csv(previsoes_path, names=['letreiro_linha', 'num_regs', 'taxa_previsao'], sep='|')
                df_previsoes['taxa_previsao'] = df_previsoes['taxa_previsao'] * 100  # Para %
            else:
                df_previsoes = pd.DataFrame()

            # Carregar geografia linhas top
            geo_path = os.path.join(relatorios_path, 'geografia_linhas_top.txt')
            if os.path.exists(geo_path):
                df_geo = pd.read_csv(geo_path, names=['letreiro_linha', 'avg_lat', 'avg_lon', 'num_posicoes'], sep='|')
            else:
                df_geo = pd.DataFrame()

            # Carregar CSV de m√©tricas (se existir)
            csv_path = os.path.join(relatorios_path, 'metrica_linhas_top.csv')
            if os.path.exists(csv_path):
                df_csv = pd.read_csv(csv_path)
                df_csv['id_onibus'] = df_csv['id_onibus'].astype(int)  # Contagem
            else:
                df_csv = pd.DataFrame()

            return df_previsoes, df_geo, df_csv
        except Exception as e:
            st.error(f"Erro ao carregar insights ETL: {e}")
            return pd.DataFrame(), pd.DataFrame(), pd.DataFrame()

    # Carregar insights ETL
    relatorios_path = 'analise_banco_dados/relatorios'
    df_previsoes, df_geo, df_csv = load_etl_insights(relatorios_path)

    # --- Abas para organizar o conte√∫do ---
    tab_mapa, tab_parados, tab_comboios, tab_qualidade = st.tabs(["üìç Mapa da Frota", "üõë √înibus Parados", "üöç Comboios de √înibus", "üìä Qualidade ETL e Insights"])

    with tab_mapa:
        st.subheader(f"Exibindo a √∫ltima posi√ß√£o conhecida para: {linha_selecionada}")
        df_mapa_latest = df_mapa.sort_values('timestamp_analise').drop_duplicates(subset=['id_onibus'], keep='last')
        df_mapa_latest = df_mapa_latest.rename(columns={'posicao_atual_lat': 'lat', 'posicao_atual_lon': 'lon'})
        if not df_mapa_latest[['lat', 'lon']].empty:
            # Filtro adicional para dados completos (se previs√µes dispon√≠veis no df)
            if 'proximo_ponto_previsto' in df_raw.columns:
                df_completa_map = df_raw.dropna(subset=['proximo_ponto_previsto'])
                if linha_selecionada != "Todas":
                    df_completa_map = df_completa_map[df_completa_map['letreiro_linha'] == linha_selecionada]
                df_mapa_latest_completa = df_completa_map.sort_values('timestamp_analise').drop_duplicates(subset=['id_onibus'], keep='last')
                df_mapa_latest_completa = df_mapa_latest_completa.rename(columns={'posicao_atual_lat': 'lat', 'posicao_atual_lon': 'lon'})
                if not df_mapa_latest_completa.empty:
                    st.map(df_mapa_latest_completa[['lat', 'lon']])
                    st.info(f"Mapa filtrado para {len(df_mapa_latest_completa)} √¥nibus com previs√µes completas.")
                else:
                    st.warning("Nenhum dado completo para filtro de previs√µes na sele√ß√£o atual.")
            else:
                st.map(df_mapa_latest[['lat', 'lon']].dropna())
        else:
            st.warning("N√£o h√° dados de localiza√ß√£o para a sele√ß√£o atual.")

    with tab_parados:
        st.subheader("Detec√ß√£o de Anomalias: √înibus Parados")
        st.markdown("A an√°lise abaixo identifica √¥nibus que ficaram parados por mais de 10 minutos com deslocamento inferior a 100 metros, um forte indicador de problemas como quebras ou tr√¢nsito extremo.")
        if onibus_parados_df.empty:
            st.success("Nenhum √¥nibus atendeu aos crit√©rios de 'parado' durante o per√≠odo analisado.")
        else:
            st.write(f"**Resultado:** Encontrados **{len(onibus_parados_df)}** √¥nibus potencialmente parados.")
            contagem_por_linha = onibus_parados_df.groupby('letreiro_linha').size().sort_values(ascending=False)
            contagem_enriquecida = enrich_with_line_names(contagem_por_linha.to_frame(name='contagem'), df_linhas)
            st.dataframe(contagem_enriquecida)
            
            st.info("""
            **Interpretando a Contagem:** A coluna 'contagem' representa o n√∫mero de **ve√≠culos √∫nicos** de cada linha que atenderam aos crit√©rios de 'parado'. 
            
            Um valor de '1' indica que um √∫nico √¥nibus daquela linha apresentou essa anomalia durante todo o per√≠odo de coleta. O resultado sugere que os problemas de parada foram **incidentes isolados** em diversas linhas, e n√£o um problema cr√¥nico concentrado em uma √∫nica linha.
            """)

            st.markdown("**Coment√°rio:** As linhas listadas acima foram as que apresentaram maior incid√™ncia de √¥nibus parados, sugerindo rotas com maior potencial de problemas operacionais ou de tr√¢nsito.")

    with tab_comboios:
        st.subheader("Detec√ß√£o de Anomalias: Comboios de √înibus")
        st.markdown("Esta an√°lise detecta eventos onde m√∫ltiplos √¥nibus da mesma linha se agrupam a menos de 200 metros um do outro, um sinal de irregularidade na frequ√™ncia.")
        if bunched_df.empty:
            st.success("Nenhum evento de 'comboio' foi detectado.")
        else:
            st.write(f"**Resultado:** Detectados **{len(bunched_df)}** eventos de 'comboio'.")
            contagem_por_linha = bunched_df.groupby('letreiro_linha').size().sort_values(ascending=False)
            contagem_enriquecida = enrich_with_line_names(contagem_por_linha.to_frame(name='contagem'), df_linhas)
            st.bar_chart(contagem_enriquecida['contagem'])
            st.markdown("**Coment√°rio:** O gr√°fico acima mostra as linhas com maior ocorr√™ncia de 'comboios'. Linhas com muitas ocorr√™ncias podem ter problemas de regularidade na opera√ß√£o, causando longas esperas para passageiros seguidas da chegada de m√∫ltiplos ve√≠culos juntos.")

    with tab_qualidade:
        st.subheader("Qualidade de Dados ETL e Insights Gerados")
        st.markdown("Esta aba mostra m√©tricas de qualidade do ETL ( % completude de previs√µes) e insights geogr√°ficos para linhas top, baseado em an√°lises filtradas na pasta `analise_banco_dados/relatorios/`.")

        if not df_previsoes.empty:
            st.subheader("Taxa de Completude de Previs√µes por Linha (Top 10)")
            fig_previsoes = st.bar_chart(df_previsoes.set_index('letreiro_linha')['taxa_previsao'], use_container_width=True)
            st.dataframe(df_previsoes.round(2))
            st.info("Linhas com >80% de completude s√£o ideais para an√°lises de tempo de chegada confi√°veis.")

        if not df_geo.empty:
            st.subheader("M√©tricas Geogr√°ficas: Centroides de Rotas para Linhas Top")
            df_geo_display = df_geo.copy()
            df_geo_display['regiao_estimada'] = df_geo_display.apply(lambda row: 'Centro SP' if -23.55 < row['avg_lat'] < -23.57 and -46.65 < row['avg_lon'] < -46.55 else 'Zona Leste' if row['avg_lon'] > -46.65 else 'Zona Oeste', axis=1)
            # Selectbox interativo para linha espec√≠fica
            linha_geo = st.selectbox("Selecione uma linha para detalhes geogr√°ficos:", df_geo_display['letreiro_linha'].tolist())
            if linha_geo:
                linha_details = df_geo_display[df_geo_display['letreiro_linha'] == linha_geo].iloc[0]
                col1, col2, col3 = st.columns(3)
                col1.metric("Avg Latitude", f"{linha_details['avg_lat']:.6f}")
                col2.metric("Avg Longitude", f"{linha_details['avg_lon']:.6f}")
                col3.metric("N√∫mero de Posi√ß√µes", linha_details['num_posicoes'])
                st.info(f"Regi√£o estimada: {linha_details['regiao_estimada']} ‚Äì Ideal para otimiza√ß√£o de rotas locais.")
            st.dataframe(df_geo_display.round(6))

        if not df_csv.empty:
            st.subheader("M√©tricas Detalhadas de Linhas Confi√°veis (de An√°lise Filtrada)")
            # Selectbox para filtrar CSV
            linha_csv = st.selectbox("Selecione uma linha do CSV para visualizar:", df_csv.index.tolist() if not df_csv.empty else [])
            if linha_csv:
                linha_csv_data = df_csv.loc[linha_csv:linha_csv]
                st.dataframe(linha_csv_data.round(6))
            else:
                st.dataframe(df_csv.round(6))
            st.info("Contagens de registros por linha ap√≥s filtro de dados completos; √∫til para priorizar dashboard.")

        # Gr√°fico interativo adicional para tend√™ncias geogr√°ficas (se df_csv dispon√≠vel)
        if not df_csv.empty:
            st.subheader("Tend√™ncias Geogr√°ficas nas Linhas Top")
            # Gr√°fico de barras para num registros vs avg lat/lon (normalizado)
            df_plot = df_csv.reset_index()
            col_plot1, col_plot2 = st.columns(2)
            with col_plot1:
                st.bar_chart(df_plot.set_index('letreiro_linha')['id_onibus'])
            with col_plot2:
                st.line_chart(df_plot.set_index('letreiro_linha')[['posicao_atual_lat', 'posicao_atual_lon']])
            st.info("Gr√°ficos interativos: Barras para volume; Linha para varia√ß√£o geogr√°fica por linha ‚Äì clique para zoom.")

        if df_previsoes.empty and df_geo.empty and df_csv.empty:
            st.warning("Nenhum relat√≥rio de insights dispon√≠vel ainda. Execute an√°lises para gerar dados na pasta relatorios/.")
